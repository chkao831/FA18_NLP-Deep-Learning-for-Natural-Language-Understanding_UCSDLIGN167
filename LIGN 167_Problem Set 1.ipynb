{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIGN 167: Problem Set 1\n",
    "### Name: Chih-Hsuan Kao\n",
    "### Date: October 5, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given two numpy array return estimated value of the slope\n",
    "import numpy as np\n",
    "def compute_slope_estimator(x, y):\n",
    "    sumX=sumY=sumXY=sumXsquare=0;\n",
    "    for i in range(len(x)):\n",
    "        sumXY = sumXY + x[i] * y[i]\n",
    "        sumXsquare = sumXsquare + x[i]*x[i]\n",
    "    slope = (sumXY - len(x)*np.average(x)*np.average(y))/(sumXsquare - len(x)*np.average(x)*np.average(x))\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given two numpy array x,y return the value of intercept b\n",
    "def compute_intercept_estimator(x,y):\n",
    "    return (np.average(y) - compute_slope_estimator(x,y) * np.average(x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given two array return the tuple of values\n",
    "def train_model(x,training_set):\n",
    "    return(compute_slope_estimator(x,training_set) , compute_intercept_estimator(x,training_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given four paramter return numpy array y\n",
    "#x_vals=[1,2,3,4]\n",
    "#a=1\n",
    "#b=1\n",
    "#sd=1\n",
    "##########################################\n",
    "def sample_linear_model(x,slope,intercept,sd):\n",
    "    y = np.zeros(shape=(len(x),1))\n",
    "    epsilon = np.random.normal(0, sd, len(x))\n",
    "    for i in range(len(x)):\n",
    "        y[i] = slope*x[i]+intercept+epsilon[i]\n",
    "    return y\n",
    "\n",
    "#g=sample_linear_model(x_vals,a,b,sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return a list of dataset\n",
    "\n",
    "#x=[1,2,3,4]\n",
    "#slope=1\n",
    "#intercept=1\n",
    "#sd=1\n",
    "#n=2\n",
    "\n",
    "def sample_datasets(x,slope,intercept,sd,n):\n",
    "    t = []\n",
    "    for i in range(n):\n",
    "        t.append(sample_linear_model(x,slope,intercept,sd))\n",
    "    return t\n",
    "\n",
    "#g=sample_datasets(x,slope,intercept,sd,n)\n",
    "#g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_estimated_slope(x_vals,a=1,b=1,sd=1):\n",
    "    n = 1000\n",
    "    trainingSet = sample_datasets(x_vals,a,b,sd,n)\n",
    "    sumSlope=0\n",
    "    for i in range(n):\n",
    "        sumSlope = sumSlope + compute_slope_estimator(x_vals, trainingSet[i])\n",
    "    return sumSlope/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 7 <br>\n",
    "Free response answer:\n",
    "As n increase the average estimated slope become more accurate.\n",
    "Initially, n=5 the slope was 0.998208.\n",
    "Then, n=10, the slope was 0.98593583.\n",
    "Finally, n=1000, the slope was 1.00140381, which was close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the different value of x_vals\n",
    "\n",
    "#test code is commented out below\n",
    "\n",
    "x_vals = np.linspace(0,1,5)\n",
    "a= compute_average_estimated_slope(x_vals)\n",
    "#print(\"n=5: \",a)\n",
    "x_vals = np.linspace(0,1,100)\n",
    "a= compute_average_estimated_slope(x_vals)\n",
    "#print(\"n=100: \",a)\n",
    "x_vals = np.linspace(0,1,1000)\n",
    "a= compute_average_estimated_slope(x_vals)\n",
    "#print(\"n=1000: \",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 8 <br>\n",
    "Free response answer: As n increase the estimated error decrease. Initially, n=5 the error was 1.602. Then, n=10, the error was 0.11709. Finally, n=1000, the error was 0.01118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 8 retrun the average square error of the estimated slope\n",
    "def compute_estimated_slope_error(x_vals,a=1,b=1,sd=1):\n",
    "    n = 1000\n",
    "    trainingSet = sample_datasets(x_vals,a,b,sd,n)\n",
    "    sumSlope=0\n",
    "    for i in range(n):\n",
    "        sumSlope = sumSlope + (1 - (compute_slope_estimator(x_vals, trainingSet[i])))*(1 - (compute_slope_estimator(x_vals, trainingSet[i])))\n",
    "    return sumSlope/1000\n",
    "\n",
    "x_vals = np.linspace(0,1,5)\n",
    "a= compute_estimated_slope_error(x_vals)\n",
    "#print(\"n=5: \",a)\n",
    "x_vals = np.linspace(0,1,100)\n",
    "a= compute_estimated_slope_error(x_vals)\n",
    "#print(\"n=100: \",a)\n",
    "x_vals = np.linspace(0,1,1000)\n",
    "a= compute_estimated_slope_error(x_vals)\n",
    "#print(\"n=1000: \",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 9: <br>\n",
    "Free response answer: As n increase the histagram plot become more concetrate to the mean 1.My plot use the automatic bin option. Therefore, the plotslooks like the same, but the x axis is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#n=5 problem9\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x_vals = np.linspace(0,1,5)\n",
    "a= compute_estimated_slope_error(x_vals)\n",
    "a = 1\n",
    "b = 1    \n",
    "sd = 1\n",
    "n = 1000\n",
    "trainingSet = sample_datasets(x_vals,a,b,sd,n)\n",
    "x=np.zeros(shape=(1000,1))\n",
    "for i in range(n):\n",
    "    x[i] = (compute_slope_estimator(x_vals, trainingSet[i]))\n",
    "n,bins,patches = plt.hist(x,bins='auto',facecolor='blue',alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#n=100 problem9\n",
    "x_vals = np.linspace(0,1,100)\n",
    "a= compute_estimated_slope_error(x_vals)\n",
    "a = 1\n",
    "b = 1    \n",
    "sd = 1\n",
    "n = 1000\n",
    "trainingSet = sample_datasets(x_vals,a,b,sd,n)\n",
    "x=np.zeros(shape=(1000,1))\n",
    "for i in range(n):\n",
    "    x[i] = (compute_slope_estimator(x_vals, trainingSet[i]))\n",
    "n,bins,patches = plt.hist(x,bins='auto',facecolor='blue',alpha=0.5)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADidJREFUeJzt3X+MZfVdxvH3I1uChSI/dkDcBZbqppSYNiUjwda0lfUPQONSKRFS2xU32cQg9hcR6h+y1RjbxIg20ZoVsNumoUXEQBQ1ZAshprDpUCiFLi0rKmxBdmqBWmss6Mc/7kE3MLNz55575858eb+SzT3n3HPvee7O7LPfOb8mVYUkqV0/MO0AkqTJsuglqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjVs37QAA69evr02bNk07hiStKffff/+3qmpmqfVWRdFv2rSJubm5aceQpDUlyb8Ms567biSpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXGr4spYaa3auXNlXyeNwhG9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXFeMKVmeBGStLAlR/RJbkxyMMnDhyw7IcmdSR7rHo/vlifJJ5LsT/JQkrMnGV6StLRhdt18Cjj/ZcuuAfZU1WZgTzcPcAGwufuzA/jkeGJKkka1ZNFX1T3At1+2eCuwu5veDVx0yPJP18B9wHFJThlXWEnS8o16MPbkqnoaoHs8qVu+AXjykPUOdMteIcmOJHNJ5ubn50eMIUlayrjPuskCy2qhFatqV1XNVtXszMzMmGNIkl4yatE/89Iume7xYLf8AHDqIettBJ4aPZ4kqa9Ri/52YFs3vQ247ZDl7+vOvjkXeP6lXTySpOlY8jz6JDcB7wTWJzkAXAt8DLg5yXbgCeCSbvU7gAuB/cD3gMsnkFmStAxLFn1VXbbIU1sWWLeAK/qGkiSNj7dAkKTGWfSS1DiLXpIaZ9FLUuO8e6W0xox6l07v7vnq5Yhekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGeR69VhXP9ZbGzxG9JDXOopekxln0ktQ499FLU+CxCK0kR/SS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJalyvok/ywSSPJHk4yU1JjkpyRpK9SR5L8vkkR44rrCRp+UYu+iQbgF8HZqvqx4EjgEuBjwPXVdVm4Flg+ziCSpJG03fXzTrgB5OsA14LPA2cB9zSPb8buKjnNiRJPYxc9FX1TeD3gScYFPzzwP3Ac1X1YrfaAWBD35CSpNH12XVzPLAVOAP4EeBo4IIFVq1FXr8jyVySufn5+VFjSJKW0GfXzc8A/1RV81X1AnAr8FbguG5XDsBG4KmFXlxVu6pqtqpmZ2ZmesSQJB1On6J/Ajg3yWuTBNgCfA24C3h3t8424LZ+ESVJffTZR7+XwUHXLwNf7d5rF3A18KEk+4ETgRvGkFOSNKJevxy8qq4Frn3Z4seBc/q8ryRpfLwyVpIa12tELy1m585pJ5D0Ekf0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGrdu2gEkrYydO6fzWk2fI3pJalyvok9yXJJbkjyaZF+Sn0xyQpI7kzzWPR4/rrCSpOXrO6L/I+DvqupM4M3APuAaYE9VbQb2dPOSpCkZueiTHAu8HbgBoKq+X1XPAVuB3d1qu4GL+oaUJI2uz4j+9cA88OdJHkhyfZKjgZOr6mmA7vGkMeSUJI2oT9GvA84GPllVbwH+g2XspkmyI8lckrn5+fkeMSRJh9On6A8AB6pqbzd/C4PifybJKQDd48GFXlxVu6pqtqpmZ2ZmesSQJB3OyEVfVf8KPJnkDd2iLcDXgNuBbd2ybcBtvRJKknrpe8HUlcBnkxwJPA5czuA/j5uTbAeeAC7puQ1JUg+9ir6qHgRmF3hqS5/3lSSNj7dAkLSkUW+B4K0TVgdvgSBJjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuM8j16L8hxoqQ2O6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIa17vokxyR5IEkf93Nn5Fkb5LHknw+yZH9Y0qSRjWOEf37gX2HzH8cuK6qNgPPAtvHsA1J0oh6FX2SjcDPAtd38wHOA27pVtkNXNRnG5Kkftb1fP0fAr8BvK6bPxF4rqpe7OYPABsWemGSHcAOgNNOO61nDB3Ozp3TTiBpmkYe0Sf5OeBgVd1/6OIFVq2FXl9Vu6pqtqpmZ2ZmRo0hSVpCnxH924CfT3IhcBRwLIMR/nFJ1nWj+o3AU/1jSpJGNfKIvqo+UlUbq2oTcCnwhap6D3AX8O5utW3Abb1TSpJGNonz6K8GPpRkP4N99jdMYBuSpCH1PRgLQFXdDdzdTT8OnDOO95Uk9eeVsZLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcWO5TbEkLaTP7yv2dx2PjyN6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY3zFghrhJeD69Vm1O95/628kiN6SWqcRS9JjbPoJalxIxd9klOT3JVkX5JHkry/W35CkjuTPNY9Hj++uJKk5eozon8R+HBVvRE4F7giyVnANcCeqtoM7OnmJUlTMnLRV9XTVfXlbvrfgX3ABmArsLtbbTdwUd+QkqTRjWUffZJNwFuAvcDJVfU0DP4zAE4axzYkSaPpXfRJjgH+EvhAVX1nGa/bkWQuydz8/HzfGJKkRfQq+iSvYVDyn62qW7vFzyQ5pXv+FODgQq+tql1VNVtVszMzM31iSJIOo89ZNwFuAPZV1R8c8tTtwLZuehtw2+jxJEl99bkFwtuA9wJfTfJgt+w3gY8BNyfZDjwBXNIvoiSpj5GLvqr+AcgiT28Z9X0lSePllbGS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktS4PrdA0Aj8DfWSVpojeklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4T6+UpM6opz+v9tOmHdFLUuMc0UtqymofXU+DI3pJapxFL0mNs+glqXEWvSQ1zqKXpMZ51s0IPKovaS1xRC9JjVvzI/o+o2tH5pLGYbX3kCN6SWrcmh/R9+GIXtKrgSN6SWrcRIo+yflJvp5kf5JrJrENSdJwxl70SY4A/hi4ADgLuCzJWePejiRpOJMY0Z8D7K+qx6vq+8DngK0T2I4kaQiTKPoNwJOHzB/olkmSpmASZ91kgWX1ipWSHcCObva7Sb4+gSwLWQ98a4W2NQlrPT+s/c9g/ulb65/h//J/9KO93uf0YVaaRNEfAE49ZH4j8NTLV6qqXcCuCWz/sJLMVdXsSm93XNZ6flj7n8H807fWP8NK55/ErpsvAZuTnJHkSOBS4PYJbEeSNISxj+ir6sUkvwb8PXAEcGNVPTLu7UiShjORK2Or6g7gjkm89xis+O6iMVvr+WHtfwbzT99a/wwrmj9VrzhOKklqiLdAkKTGNVv0S92GIcl1SR7s/nwjyXPTyLmYIfKfluSuJA8keSjJhdPIuZgh8p+eZE+X/e4kG6eRczFJbkxyMMnDizyfJJ/oPt9DSc5e6YyHM0T+M5Pcm+S/kly10vmGMcRneE/3d/9Qki8mefNKZzycIfJv7bI/mGQuyU9NLExVNfeHwUHgfwReDxwJfAU46zDrX8ngoPHUsw+bn8E+vl/tps8C/nnauZeZ/y+Abd30ecBnpp37ZfneDpwNPLzI8xcCf8vgupFzgb3TzrzM/CcBPwH8LnDVtPOO+BneChzfTV+wBr8Gx/D/u8/fBDw6qSytjuiXexuGy4CbViTZcIbJX8Cx3fQPscC1ClM0TP6zgD3d9F0LPD9VVXUP8O3DrLIV+HQN3Accl+SUlUm3tKXyV9XBqvoS8MLKpVqeIT7DF6vq2W72PgbX7KwaQ+T/bnUtDxzNAheWjkurRT/0bRiSnA6cAXxhBXINa5j8O4FfSnKAwRlOV65MtKEMk/8rwMXd9LuA1yU5cQWyjYu3+lhdtjP4CWtNSfKuJI8CfwP8yqS202rRD3Ubhs6lwC1V9d8TzLNcw+S/DPhUVW1ksBvhM0lWy9dzmPxXAe9I8gDwDuCbwIuTDjZGy/ke0wQl+WkGRX/1tLMsV1X9VVWdCVwE/M6kttPqb5ga6jYMnUuBKyaeaHmGyb8dOB+gqu5NchSD+2ccXJGEh7dk/qp6CvgFgCTHABdX1fMrlrC/5XyPaUKSvAm4Hrigqv5t2nlGVVX3JPnRJOurauz38FktI8BxG+o2DEneABwP3LvC+ZYyTP4ngC0ASd4IHAXMr2jKxS2ZP8n6Q34C+Qhw4wpn7Ot24H3d2TfnAs9X1dPTDvVqkuQ04FbgvVX1jWnnWa4kP5Yk3fTZDE5cmMh/Vk2O6GuR2zAk+W1grqpeKp3LgM8dckBkVRgy/4eBP0vyQQa7DH55tXyOIfO/E/i9JAXcwyr7qSrJTQwyru+Og1wLvAagqv6UwXGRC4H9wPeAy6eTdGFL5U/yw8AcgwP6/5PkAwzOjPrOlCK/whBfg98CTgT+pOvLF2sV3ehsiPwXMxgsvAD8J/CLk/o37JWxktS4VnfdSJI6Fr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY37XyXyPCPtkbE+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#n=1000 problem9\n",
    "x_vals = np.linspace(0,1,1000)\n",
    "a= compute_estimated_slope_error(x_vals)\n",
    "a = 1\n",
    "b = 1    \n",
    "sd = 1\n",
    "n = 1000\n",
    "trainingSet = sample_datasets(x_vals,a,b,sd,n)\n",
    "x=np.zeros(shape=(1000,1))\n",
    "for i in range(n):\n",
    "    x[i] = (compute_slope_estimator(x_vals, trainingSet[i]))\n",
    "n,bins,patches = plt.hist(x,bins='auto',facecolor='blue',alpha=0.5)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 10 <br>\n",
    "return the average square different btw arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the average square different btw arrays\n",
    "#y=[1,1,1,1]\n",
    "#y_hat=[4,4,4,4]\n",
    "\n",
    "def calculate_prediction_error(y, y_hat):\n",
    "    sumError=0\n",
    "    for i in range(len(y)):\n",
    "        sumError = sumError + (y[i]-y_hat[i])*(y[i]-y_hat[i])\n",
    "    return sumError / len(y)\n",
    "\n",
    "#b=calculate_prediction_error(y, y_hat)\n",
    "#b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 11 <br>\n",
    "Free response answer: As n increase the average_training_set_error increase and become more close to the vlaue 1. I suppose the reason is that we are testing the set with our training set. Since we have train our slope and intercept based on the training set already, the slope and intercept wereto desgined to be fit our data. That is the reason why all error over here was less than 1. And also the more data we consider would slightly increase the error but the sum will be less than one.\n",
    "\n",
    "Initially, n=5 the slope was 0.60149. Then, n=10, the slope was 0.97660019. Finally, n=1000, the slope was 0.992678, which was closer to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=5:  [0.60443282]\n",
      "n=100:  [0.98186765]\n",
      "n=1000:  [0.99975183]\n"
     ]
    }
   ],
   "source": [
    "def average_training_set_error(x_vals,a=1,b=1,sd=1):\n",
    "    n = 1000\n",
    "    #define vector\n",
    "    slope_estimator= intercept_estimator=y_hat = predict_error =0\n",
    "    #set up 1000 training set\n",
    "    trainingSet = sample_datasets(x_vals,a,b,sd,n)\n",
    "    for i in range(n):\n",
    "        #Calculate the estimator of the slope and the intercept\n",
    "        slope_estimator = compute_slope_estimator(x_vals, trainingSet[i])\n",
    "        intercept_estimator= compute_intercept_estimator(x_vals, trainingSet[i])         \n",
    "        #use the estimated slope and intercept to compute predicted value y_hat\n",
    "        y_hat = slope_estimator * x_vals + intercept_estimator\n",
    "        \n",
    "        #use the cuntion to compute the predicted value y_hat and the store it in a numpy array\n",
    "        predict_error = predict_error+ calculate_prediction_error(trainingSet[i], y_hat)\n",
    "    return predict_error / n\n",
    "\n",
    "x_vals = np.linspace(0,1,5)\n",
    "a= average_training_set_error(x_vals)\n",
    "print(\"n=5: \",a)\n",
    "x_vals = np.linspace(0,1,100)\n",
    "a= average_training_set_error(x_vals)\n",
    "print(\"n=100: \",a)\n",
    "x_vals = np.linspace(0,1,1000)\n",
    "a= average_training_set_error(x_vals)\n",
    "print(\"n=1000: \",a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 12 <br>\n",
    "Free response answer: As n increase the average_training_set_error decrease and become more close to the vlaue 1. This is much more intuitively correct. The more the data, the less the error.\n",
    " \n",
    "Initially, n=5 the set error was 1.303. Then, n=10, the set error was 1.022. Finally, n=1000, the set error was 1.008, which was closer to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=5:  [1.33229339]\n",
      "n=100:  [1.02157762]\n",
      "n=1000:  [1.00287442]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def average_test_set_error(x_vals,a=1,b=1,sd=1):\n",
    "    n = 1000\n",
    "    #define vector\n",
    "    predict_error = 0\n",
    "    slope_estimator= intercept_estimator=y_hat = predict_error =0\n",
    "    #set up 1000 training set\n",
    "    trainingSet = sample_datasets(x_vals,a,b,sd,n)\n",
    "    for i in range(n):\n",
    "        #Calculate the estimator of the slope and the intercept\n",
    "        slope_estimator = compute_slope_estimator(x_vals, trainingSet[i])\n",
    "        intercept_estimator= compute_intercept_estimator(x_vals, trainingSet[i])         \n",
    "        #use the estimated slope and intercept to compute predicted value y_hat\n",
    "        y_hat = slope_estimator * x_vals + intercept_estimator\n",
    "        \n",
    "        #use the cuntion to compute the predicted value y_hat and the store it in a numpy array\n",
    "        predict_error = predict_error+ calculate_prediction_error(sample_linear_model(x_vals,a,b,sd), y_hat)\n",
    "    return predict_error / n\n",
    "\n",
    "x_vals = np.linspace(0,1,num=5)\n",
    "a= average_test_set_error(x_vals)\n",
    "print(\"n=5: \",a)\n",
    "x_vals = np.linspace(0,1,num=100)\n",
    "a= average_test_set_error(x_vals)\n",
    "print(\"n=100: \",a)\n",
    "x_vals = np.linspace(0,1,num=1000)\n",
    "a= average_test_set_error(x_vals)\n",
    "print(\"n=1000: \",a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
